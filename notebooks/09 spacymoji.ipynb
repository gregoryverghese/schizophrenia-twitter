{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code tha\n",
    "t uses spaceyMoji to tokenize our text. This gets around the nltk problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from spacymoji import Emoji\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import nltk\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "annSchiz1 = pd.read_csv('data/baseline/dataOut/annSchiz1.csv', encoding='utf-8')\n",
    "annSchiz2 = pd.read_csv('data/baseline/dataOut/annSchiz2.csv', encoding='utf-8')\n",
    "nonAnnSchizFile = pd.read_csv('data/dataIn/schiz/nonAnnFinalSchiz.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(emoji, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEmoji(sent, check=False):\n",
    "    doc = nlp(sent)\n",
    "    if doc._.has_emoji==check:\n",
    "        sent = np.nan\n",
    "    return sent\n",
    "\n",
    "def getEmojiDf(df, check=False):\n",
    "    dfNew = df.copy()\n",
    "    dfNew['Tweet'] = dfNew['Tweet'].apply(lambda x: checkEmoji(x, check))\n",
    "    dfNew = dfNew.dropna()\n",
    "    return dfNew\n",
    "\n",
    "def removeEmojis(sent):\n",
    "    doc = nlp(sent)\n",
    "    tokens = [token.text for token in doc if not token._.is_emoji]\n",
    "    sent = ' '.join(tokens)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31\n",
       "0    25\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojiDf = getEmojiDf(annSchiz1)\n",
    "emojiDf.to_csv('data/baseline/emoji/emSchiz1Em.csv')\n",
    "emojiDf['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noEmojiDf = emojiDf.copy()\n",
    "noEmojiDf['Tweet'] = noEmojiDf['Tweet'].apply(lambda x: removeEmojis(x))\n",
    "noEmojiDf.to_csv('data/baseline/emoji/Schiz1Em.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15\n",
       "0    13\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojiDf = getEmojiDf(annSchiz2)\n",
    "emojiDf.to_csv('data/baseline/emoji/emSchiz2Em.csv')\n",
    "emojiDf['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noEmojiDf = emojiDf.copy()\n",
    "noEmojiDf['Tweet'] = noEmojiDf['Tweet'].apply(lambda x: removeEmojis(x))\n",
    "noEmojiDf.to_csv('data/baseline/emoji/Schiz2Em.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = [2, 3, 4, 5]\n",
    "window = [2, 3 , 4, 5]\n",
    "size = [25, 50, 100, 200]\n",
    "sample=6e-5\n",
    "alpha=0.05\n",
    "min_alpha=0.0007 \n",
    "negative=20\n",
    "sgTrain = 1\n",
    "cbowTrain = 0\n",
    "emArgs = [min_count[0], window[0], size[3], sample, alpha, min_alpha, negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeTweet(sent):\n",
    "    doc = nlp(sent)\n",
    "    tokens= [t.text.strip() for t in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "nonAnnSchiz = nonAnnSchizFile[['Tweet','true_false']]\n",
    "#emojiDf = getEmojiDf(nonAnnSchiz)\n",
    "emojitokens = nonAnnSchiz['Tweet'].apply(lambda x: tokenizeTweet(x))\n",
    "emojitokens.to_csv('data/dataOut/schiz/emoji/nonAnnFinalSchizEmoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "charTokens = nonAnnSchiz['Tweet'].apply(lambda x: list(x))\n",
    "charTokens.to_csv('data/dataOut/schiz/emoji/nonAnnFinalSchizEmojiChar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmoticonText(tokens):\n",
    "\n",
    "    emojiLines = list(map(lambda x: any(t._.is_emoji for t in x), tokens))\n",
    "    tokens = np.array(tokens)\n",
    "    emojiLines = np.array(emojiLines)\n",
    "  \n",
    "    tokens = tokens[emojiLines]\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiLst = []\n",
    "y = emojiDf['Tweet'].tolist()\n",
    "for t in y:\n",
    "    doc = nlp(t)\n",
    "    for token in doc:\n",
    "        if token._.is_emoji:\n",
    "            emojiLst.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojitokens = annSchiz2['Tweet'].apply(lambda x: tokenizeTweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojiDf = getEmojiDf(annSchiz2)\n",
    "len(emojiDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = emojiDf['Tweet'].apply(lambda x: nltk.word_tokenize(x))\n",
    "x = z.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "emojitokens.to_csv('data/dataOut/schiz/emoji/annSchiz2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "emojitokens = annSchiz2['Tweet'].apply(lambda x: list(x))\n",
    "emojitokens.to_csv('data/dataOut/schiz/emoji/annSchizChar2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
