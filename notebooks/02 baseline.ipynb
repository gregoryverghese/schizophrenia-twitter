{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model, focuses on feature engineering traditional NLP techniques such as tfidf, sentiment and subjectivity\n",
    "#List can be found in feature_engineering script. Uses these to feed a range of classifiers - Random Forest, SVM,\n",
    "#Gradient Boost, Naive Bayes and K-nearest Neighbour - details of code can be found in ml script. Uses a cross-validation\n",
    "#approach with five folds for on first annotated set of data. Second set of annotated data used as holdout for pure\n",
    "#testing purposes. We also filter tweets that have emoticons and compare the performance with the same tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility\n",
    "import evaluation1 as ev\n",
    "import feature_engineering1 as fe1\n",
    "import feature_engineering as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, cross_val_predict, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob as tb\n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import spacy\n",
    "from spacymoji import Emoji\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "nlp = spacy.load('en')\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(emoji, first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviation list created compiled manually, contains just under 600 abbreviations. Also set the suite classifier used in the baseline model. To add a classifier add it to the methods list and a corresponding function to ML class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = pd.read_csv('data/other/abbreviations.csv')['Abbreviation'].tolist()\n",
    "abbreviations = [str(a).strip() for a in abbreviations]\n",
    "methods = ['RandomForest', 'GradientBoost', 'KNN', 'SVM', 'NaiveBayes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data (Already preprocessed using 01 preprocessing notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'data/baseline/dataOut/annSchiz1.csv'\n",
    "fileName2 = 'data/baseline/dataOut/annSchiz2.csv'\n",
    "socialDf = pd.read_csv(fileName, encoding = 'utf-8')\n",
    "socialDf2 = pd.read_csv(fileName2, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions generate the features using the FeatureEngineering class in the fe script that contains code for tf-idf model (getTFIDF) and desciptive features (getFeatures) such as sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get descriptive features such as sentiment\n",
    "from the FeatureEngineering scropt inside the\n",
    "fe script\n",
    "'''\n",
    "def getFeatures(socialDf):\n",
    "    featuresEm = fe.FeatureEngineering(socialDf)\n",
    "    tweets = features.getFeatures('Tweet')\n",
    "    return tweets\n",
    "\n",
    "'''\n",
    "returns only columns in dataframe that pertain to\n",
    "features\n",
    "'''\n",
    "def getFeatureColumns(tweets):\n",
    "    fCols = tweets[tweets.columns.difference([\"Tweet\", \"Classification\"])].columns\n",
    "    cols = tweets[tweets.columns.difference([\"Classification\"])].columns\n",
    "    return fCols, cols\n",
    "\n",
    "'''\n",
    "returns tf-idf vectorizer object, tf-idf matrix\n",
    "and labels\n",
    "'''\n",
    "def getTFIDF(tweets, fCols, cols):\n",
    "    tfidfAll, xVectAll, tfidf = fe.gettfidfVectors(tweets, fCols)\n",
    "    labels = tweets['Classification']\n",
    "    return tfidfAll, xVectAll, tfidf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML classifier class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class contains code to train classifiers listed in methods above. In order to add a classifier simply wrap its\n",
    "scikit-learn function in a function named getFunction() and return classifier object. This class can also perform cross-valiadtion as well training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ml class contains logic for classification across a range of classifiers\n",
    "'''\n",
    "class baseML():\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.classifiers = None\n",
    "    \n",
    "    '''\n",
    "    get cross validation results, k=5 by default\n",
    "    '''\n",
    "    def getCrossValidation(self, clf, k_fold=2):\n",
    "        return cross_val_predict(clf, self.features, self.labels, cv=k_fold, n_jobs = -1)\n",
    "\n",
    "    '''\n",
    "    get predictions for all classifiers and evaluation metrics\n",
    "    '''\n",
    "    def getAllPredictions(self, methods=['RandomForest']):\n",
    "        self.classifiers = [getattr(self,'get'+f)() for f in methods]\n",
    "        predictions = map(self.getCrossValidation, self.classifiers)\n",
    "        evaluation =  self.getEval(predictions, methods)\n",
    "        #confusion = self.getEval(predictions, methods)\n",
    "        return evaluation\n",
    "    \n",
    "    '''\n",
    "    train passed classifiers on class features and labels\n",
    "    '''\n",
    "    def trainAllClassifiers(self, methods=['RandomForest', 'GradientBoost', 'KNN', 'SVM', 'NaiveBayes']):\n",
    "        self.classifiers = [getattr(self,'get'+f)() for f in methods]\n",
    "        classifiersTrained = [clf.fit(self.features, self.labels) for clf in self.classifiers]\n",
    "        return classifiersTrained\n",
    "         \n",
    "    '''\n",
    "    initiate evaluation object from ev script and get evaluation summary\n",
    "    '''\n",
    "    def getEval(self, predict, methods=['RandomForest', 'GradientBoost', 'KNN', 'SVM', 'NaiveBayes']):\n",
    "        evalObj = ev.Evaluation([self.labels]*len(predict), predict)\n",
    "        #results = eval('evalObj.get' + method + '()')\n",
    "        results = evalObj.getSummary(methods)\n",
    "        return results\n",
    "    \n",
    "    '''\n",
    "    return random forest classifier object\n",
    "    '''\n",
    "    def getRandomForest(self, n=150):\n",
    "        randFor = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1, random_state=0)\n",
    "        return randFor\n",
    "    \n",
    "    '''\n",
    "    return gradient boost classifier object\n",
    "    '''\n",
    "    def getGradientBoost(self, n=150):\n",
    "        gradBoost = GradientBoostingClassifier(n_estimators=n, max_depth=None,  random_state=0)\n",
    "        return gradBoost\n",
    "    \n",
    "    '''\n",
    "    return k-NN classifier object\n",
    "    '''\n",
    "    def getKNN(self, n=3):\n",
    "        knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        return knn\n",
    "    \n",
    "    '''\n",
    "    return SVM classifier object\n",
    "    '''\n",
    "    def getSVM(self, kFunc='linear'):\n",
    "        svm = SVC(kernel=kFunc, probability=True)\n",
    "        return svm\n",
    "   \n",
    "    '''\n",
    "    return naive bayes classifier object\n",
    "    '''\n",
    "    def getNaiveBayes(self):\n",
    "        nb = GaussianNB()\n",
    "        return nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get baseline features, classify using \n",
    "cross-validation and store results\n",
    "'''\n",
    "def allMain(socialDf):\n",
    "    features = fe.FeatureEngineering(socialDf)\n",
    "    tweets = features.getFeatures('Tweet')\n",
    "    fCols, cols = getFeatureColumns(tweets)\n",
    "    tfidfAll, xVectAll, tfidf, labels = getTFIDF(tweets, fCols, cols)\n",
    "    ml = baseML(xVectAll, labels)\n",
    "    resultsAll = ml.getAllPredictions()\n",
    "    return resultsAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute baseline model for all tweets and save in the following path 'data/results/baseline/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsAll = allMain(socialDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = utility.getEvalDf([resultsAll], 'data/results/baseline/all', 0, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "returns important features of classifier\n",
    "'''\n",
    "def getImportantFeatures(clf, features):\n",
    "    \n",
    "    important = clf.feature_importances_\n",
    "    importantDf = pd.DataFrame({'feature': features.columns, 'importance': rf.feature_importances_})\n",
    "    importantDf = importantDf.sort_values('importance',ascending=False).set_index('feature')\n",
    "\n",
    "    return importantDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticon Only tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look only at emoticon tweets. This gets tweets containing emoticons only the same set of tweets with\n",
    "the emoticons filtered out (there are 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emSchiz1Em = pd.read_csv('data/baseline/emoji/emSchiz1Em.csv', encoding='utf-8')\n",
    "schiz1Em = pd.read_csv('data/baseline/emoji/schiz1Em.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get baseline features, classify using \n",
    "cross-validation and store results\n",
    "for emoticon tweets\n",
    "'''\n",
    "def emoticonMain(emSchiz1Em):\n",
    "    features = fe.FeatureEngineering(emSchiz1Em)\n",
    "    tweets = features.getFeatures('Tweet')\n",
    "    fCols, cols = getFeatureColumns(tweets)\n",
    "    xVectAll, labels = getTFIDF(tweets, fCols, cols)\n",
    "    ml = baseML(xVectAll, labels)\n",
    "    resultsEm = ml.getAllPredictions()\n",
    "    return resultsEm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to get performance for tweets containing emoticons only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsEm = emoticonMain(emSchiz1Em)\n",
    "results = utility.getEvalDf([resultsEm], 'data/results/baseline/emoticon', 0, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.806061</td>\n",
       "      <td>0.848095</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.908571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.797483</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.850476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.635198</td>\n",
       "      <td>0.760952</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.674286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.704139</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.879048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.583810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy        f1  precision    recall   roc_auc\n",
       "RandomForest   0.806061  0.848095   0.783333  0.938095  0.908571\n",
       "GradientBoost  0.809091  0.797483   0.876190  0.757143  0.850476\n",
       "KNN            0.645455  0.635198   0.760952  0.661905  0.674286\n",
       "SVM            0.736364  0.704139   0.863095  0.695238  0.879048\n",
       "NaiveBayes     0.609091  0.630556   0.660476  0.614286  0.583810"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "get baseline features, classify using \n",
    "cross-validation and store results\n",
    "for emoticon tweets, without emoticons\n",
    "'''\n",
    "def noEmoticonMain(schiz1Em):\n",
    "    features = fe.FeatureEngineering(schiz1Em)\n",
    "    tweets = features.getFeatures('Tweet')\n",
    "    fCols, cols = getFeatureColumns(tweets)\n",
    "    xVectAll, labels = getTFIDF(tweets, fCols, cols)\n",
    "    noMl = baseML(xVectAll, labels)\n",
    "    noResultsEm = noMl.getAllPredictions()\n",
    "    return noResultsEm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to get performance for tweets containing emoticons only, with emoticons removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "noResultsEm=noEmoticonMain(schiz1Em)\n",
    "results = utility.getEvalDf([noResultsEm], 'data/results/baseline/noEmoticon', 0, methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.851941</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.922857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.817483</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.830952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.661905</td>\n",
       "      <td>0.684286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.739472</td>\n",
       "      <td>0.840952</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.864762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.592424</td>\n",
       "      <td>0.624149</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.573810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy        f1  precision    recall   roc_auc\n",
       "RandomForest   0.822727  0.851941   0.816667  0.909524  0.922857\n",
       "GradientBoost  0.809091  0.817483   0.862857  0.785714  0.830952\n",
       "KNN            0.645455  0.633333   0.753333  0.661905  0.684286\n",
       "SVM            0.753030  0.739472   0.840952  0.723810  0.864762\n",
       "NaiveBayes     0.592424  0.624149   0.642857  0.614286  0.573810"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uppercase Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is not included in the baseline study for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLowerText(sentence, abbreviations, strip=False):\n",
    "    if any(i.isupper() and i != 'RT' and i not in abbreviations for i in sentence)==strip\n",
    "        sentence = np.nan\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = socialDf\n",
    "tokens['Tweet'] = socialDf['Tweet'].apply(lambda x: getLowerText(x, abbreviations))\n",
    "tweets = getFeatures(tokens)\n",
    "fCols, cols = getFeatureColumns(tweets)\n",
    "xVectAll, labels = getTFIDF(tweets, fCols, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = baseML(xVectAllEm, labels)\n",
    "resultsLower = ml.getAllPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = socialDf\n",
    "tokens['Tweet'] = socialDf['Tweet'].apply(lambda x: getLowerText(x, abbreviations))\n",
    "tweets = getFeatures(tokens)\n",
    "fCols, cols = getFeatureColumns(tweets)\n",
    "xVectAll, labels, xTrain, xTest, yTrain, yTest = getTFIDF(tweets, fCols, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this part looks at getting classification for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use tf-idf vectorixer on test data and get corresponding \n",
    "descriptive features and then get classification using ml\n",
    "and evaluation metrics using ml class and evaluation class\n",
    "respecitvely\n",
    "'''\n",
    "def testMain(socialDf, socialDf2):\n",
    "    \n",
    "    featuresTrain = fe.FeatureEngineering(socialDf)\n",
    "    tweetsTrain = featuresTrain.getFeatures('Tweet')\n",
    "    fCols, cols = getFeatureColumns(tweetsTrain)\n",
    "    tfidfAll, xVectAllTrain, tfidf, labelsTrain = getTFIDF(tweetsTrain, fCols, cols)\n",
    "    \n",
    "    featuresTest = fe.FeatureEngineering(socialDf2)\n",
    "    tweetsTest = featuresTest.getFeatures('Tweet')\n",
    "    fCols, cols = getFeatureColumns(tweetsTest)\n",
    "    tfidfY  = tfidf.transform(socialDf2['Tweet'])\n",
    "    labelsTest = tweetsTest['Classification']\n",
    "    xVectAllTest = fe.getFeatureArray(tweetsTest, fCols, tfidfY, tfidfAll.get_feature_names())\n",
    "    \n",
    "    ml = baseML(xVectAllTrain, labelsTrain)\n",
    "    classifiers = ml.trainAllClassifiers()\n",
    "    predictions = ml.predictAllClassifiers(classifiers, xVectAllTest)\n",
    "    \n",
    "    e = ev.Evaluation(predictions, [labelsTest]*len(predictions))\n",
    "    results = e.getSummary(['RandomForest', 'GradientBoost', 'KNN', 'SVM', 'NaiveBayes'])\n",
    "    \n",
    "    cm = [confusion_matrix(l, p) for l, p in zip([labelsTest]*len(predictions), predictions)]\n",
    "    \n",
    "    return results, cm\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, cm = testMain(socialDf, socialDf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[152,  15],\n",
       "        [ 47, 116]]), array([[141,  26],\n",
       "        [ 42, 121]]), array([[103,  64],\n",
       "        [ 87,  76]]), array([[150,  17],\n",
       "        [ 39, 124]]), array([[145,  22],\n",
       "        [ 35, 128]])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('data/results/baseline/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
